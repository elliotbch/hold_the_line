# ğŸƒâ€â™‚ï¸ Hold The Line: Guidance System for the Visually Impaired

Ce projet vise Ã  dÃ©velopper un systÃ¨me portatif permettant dâ€™aider les personnes malvoyantes Ã  se dÃ©placer en toute sÃ©curitÃ© le long dâ€™un parcours balisÃ©. En utilisant un Raspberry Pi, une camÃ©ra et un casque audio, le systÃ¨me capte en temps rÃ©el lâ€™image dâ€™une ligne sur le sol, calcule lâ€™angle entre cette ligne et la direction de lâ€™utilisateur, et fournit un retour audio stÃ©rÃ©ophonique pour guider lâ€™utilisateur. ğŸ§ğŸ“·

---

## ğŸ“‹ Table des matiÃ¨res

1. [Introduction](#introduction)
2. [Approches ExploitÃ©es](#approches-exploitÃ©es)
   - [Active Outline Model](#active-outline-model)
   - [Middle Edge Model](#middle-edge-model)
   - [Radon Transform Model](#radon-transform-model)
   - [Quantization & Middle-Sampled Linear Regression Model](#quantization--middle-sampled-linear-regression-model)
3. [Ensemble & Multi-threading](#ensemble--multi-threading)
4. [ExpÃ©riences & RÃ©sultats](#expÃ©riences--rÃ©sultats)
5. [Conclusion & Perspectives](#conclusion--perspectives)
6. [Mode d'emploi](#mode-demploi)
7. [Instructions pour DÃ©veloppeurs](#instructions-pour-dÃ©veloppeurs)
8. [Contributeurs](#contributeurs)
9. [RÃ©fÃ©rences](#rÃ©fÃ©rences)

---

## ğŸ“– Introduction

Ce projet de semestre a pour objectif de permettre aux personnes malvoyantes de se dÃ©placer en toute autonomie grÃ¢ce Ã  un systÃ¨me de guidage basÃ© sur la dÃ©tection dâ€™une ligne. En capturant en temps rÃ©el des images et en analysant leur contenu, le systÃ¨me calcule lâ€™angle entre la ligne et la direction de lâ€™utilisateur, puis fournit un retour audio permettant dâ€™ajuster le trajet. Lâ€™approche fait appel Ã  des techniques variÃ©es de traitement dâ€™image et de gestion multi-threadÃ©e sur un Raspberry Pi. ğŸ˜Š

---

## ğŸ” Approches ExploitÃ©es

Plusieurs mÃ©thodes de dÃ©tection ont Ã©tÃ© explorÃ©es pour identifier la trajectoire Ã  suivre :

### ğŸ’¡ Active Outline Model

- **Principe :** Utilise la mÃ©thode des *contours actifs* (snakes) pour segmenter lâ€™image.
- **Fonctionnement :** Le contour Ã©volue pour minimiser une fonction dâ€™Ã©nergie qui combine la fidÃ©litÃ© aux bords et la rÃ©gularitÃ© du contour.
- **Limites :** Calcul complexe et difficultÃ©s Ã  obtenir une performance en temps rÃ©el.

### âœ¨ Middle Edge Model

- **Principe :** Applique une dÃ©tection dâ€™arÃªtes via un filtre Laplacien du Gaussien (LoG).
- **Fonctionnement :**  
  1. Compression et amÃ©lioration de lâ€™image (affinage et lissage).  
  2. DÃ©tection des bords donnant deux lignes limites de la trajectoire.  
  3. Calcul du point mÃ©dian pour chaque ligne de pixels.
- **Retour Audio :** Le volume stÃ©rÃ©ophonique est ajustÃ© en fonction de la distance entre lâ€™utilisateur et la trajectoire.
- **ComplexitÃ© :** Environ O(n log(n)) grÃ¢ce Ã  lâ€™utilisation des algorithmes de transformation de Fourier rapides.

### ğŸ”„ Radon Transform Model

- **Principe :** Utilise la transformation de Radon pour identifier lâ€™orientation dominante des arÃªtes.
- **Fonctionnement :**  
  - Compression, filtrage par le dÃ©tecteur Canny, et application de la transformation de Radon pour estimer lâ€™angle de la ligne par rapport Ã  la verticale.
- **Limites :** ComplexitÃ© Ã©levÃ©e (O(nÂ²)) et temps de calcul plus long.

### ğŸ¨ Quantization & Middle-Sampled Linear Regression Model

- **Principe :** Combine la quantification de couleurs par lâ€™algorithme k-means++ et une rÃ©gression linÃ©aire sur les segments Ã©chantillonnÃ©s.
- **Fonctionnement :**  
  1. Quantification de lâ€™image pour conserver les informations de couleur sans passer au niveau de gris.  
  2. Extraction des milieux de segments de couleur similaires et application dâ€™une rÃ©gression linÃ©aire pour estimer lâ€™angle.
- **Avantage :** ComplexitÃ© linÃ©aire (O(n)) aprÃ¨s quantification, offrant des rÃ©sultats rapides et prÃ©cis.
- **Retour Audio :** Lâ€™angle estimÃ© est transformÃ© en signal audio, modulant les volumes gauche et droit.

---

## ğŸ”§ Ensemble & Multi-threading

Pour permettre un traitement en temps rÃ©el sur le Raspberry Pi, nous avons mis en place un systÃ¨me multi-threadÃ© :

- **Thread A :**  
  - ResponsabilitÃ© : Quantification des couleurs et dÃ©tection initiale de la ligne.  
  - TÃ¢che relativement lente mais essentielle pour Ã©tablir la rÃ©fÃ©rence de couleur. ğŸ§µ

- **Thread B :**  
  - ResponsabilitÃ© : DÃ©tection fine de la ligne et gÃ©nÃ©ration du signal audio de guidage en temps rÃ©el.  
  - Fonctionne en parallÃ¨le avec Thread A pour assurer une rÃ©ponse rapide. âš¡

Cette architecture permet dâ€™offrir un guidage continu et fluide Ã  lâ€™utilisateur, mÃªme si la mise Ã  jour de la rÃ©fÃ©rence de couleur se fait moins frÃ©quemment.

---

## ğŸ“Š ExpÃ©riences & RÃ©sultats

- **Environnement de Test :**  
  - Tests rÃ©alisÃ©s dans le Marconi amphi-thÃ©Ã¢tre et sur le terrain.
  
- **Performances :**  
  - Sur 20 essais, le systÃ¨me a dÃ©tectÃ© correctement la ligne Ã  chaque fois.
  - Le retour audio stÃ©rÃ©ophonique guide efficacement lâ€™utilisateur vers la trajectoire souhaitÃ©e.
  
- **Observations :**  
  - Quelques ajustements de calibration Ã©taient nÃ©cessaires pour optimiser la dÃ©tection des couleurs et rÃ©duire le bruit environnant.
  - Lâ€™approche multi-thread permet une transition fluide des signaux, amÃ©liorant lâ€™expÃ©rience utilisateur.

---

## ğŸ“ Conclusion & Perspectives

**Conclusion :**  
Le systÃ¨me "Hold The Line" dÃ©montre avec succÃ¨s quâ€™une solution basÃ©e sur le Raspberry Pi, couplÃ©e Ã  un traitement dâ€™image en temps rÃ©el et Ã  un retour audio stÃ©rÃ©ophonique, peut grandement faciliter la mobilitÃ© des personnes malvoyantes. ğŸŒŸ

**Perspectives :**  
- Optimiser la vitesse de traitement pour rÃ©duire davantage la latence.
- IntÃ©grer et amÃ©liorer les approches multiples pour une dÃ©tection plus robuste.
- Envisager une implÃ©mentation en Python pour rendre le systÃ¨me plus accessible et Ã©conomique.
- AmÃ©liorer la rÃ©sistance au bruit et la prÃ©cision de la dÃ©tection sur diffÃ©rentes surfaces.

---

## ğŸ“– Mode d'emploi

### ğŸš€ Pour les Utilisateurs

1. **Utilisation :**  
   - Allumez le systÃ¨me en appuyant sur le bouton dÃ©diÃ© (le lancement sâ€™effectue automatiquement sur le Raspberry Pi).  
   - Placez le casque et suivez les instructions audio stÃ©rÃ©ophonique pour rester centrÃ© sur la ligne.
   
2. **Mise Ã  jour du Firmware :**  
   - Connectez le Raspberry Pi Ã  lâ€™alimentation via le cÃ¢ble USB-C.  
   - TÃ©lÃ©chargez la version la plus rÃ©cente du firmware depuis notre GitLab : [GitLab Project](https://gitlab.eurecom.fr/the-win-team-a3/project-s5).  
   - Ouvrez un terminal et connectez-vous via SFTP :  
     ```
     sftp pi@holdtheline.local
     ```
   - Supprimez lâ€™ancien fichier et transfÃ©rez le nouveau :  
     ```
     rm projects5.elf
     put /chemin/vers/projects5.elf /home/pi
     ```
   - DÃ©connectez le cÃ¢ble dâ€™alimentation et redÃ©marrez en maintenant le bouton enfoncÃ©.

---

## ğŸ‘¨â€ğŸ’» Instructions pour DÃ©veloppeurs

### PrÃ©-requis logiciels :
- **MATLAB et Simulink** avec les packages de support pour Raspberry Pi.
- **Audio Toolbox** et **DSP System Toolbox**.

### Connexions matÃ©rielles :
- Connectez le Raspberry Pi Ã  la camÃ©ra, aux Ã©couteurs et Ã  la batterie.
- Utilisez un cÃ¢ble Ethernet pour le dÃ©ploiement initial depuis votre ordinateur.

### DÃ©ploiement :
1. Configurez la connexion avec le Raspberry Pi via Simulink.
2. SÃ©lectionnez le bon matÃ©riel dans les paramÃ¨tres et lancez la compilation.
3. Une fois le dÃ©ploiement terminÃ©, dÃ©branchez le Raspberry Pi et testez le systÃ¨me en conditions rÃ©elles.

Le code complet est accessible sur notre GitLab : [GitLab Repository](https://gitlab.eurecom.fr/the-win-team-a3/project-s5)

---

## ğŸ‘¥ Contributeurs

**Team A - Group 3**  
- **Elliot Bouchy**  
- **GaÃ«tan Plisson**  
- **Maxime Belpois**  
- **Lina Chiadmi**  
- **Meriem Driss**  

Sous la supervision de **RaphaÃ«l Troncy** Ã  EURECOM, Sophia Antipolis.

---

## ğŸ“š RÃ©fÃ©rences

1. Dugelay, J.-L. â€“ *Image Processing*, 2022.  
2. Todisco, M. â€“ *Sound Processing*, 2022.  
3. Galdi, C. â€“ *Computer Programming*, 2022.  
4. Magnac, M.-A. â€“ *Digital Responsibility*, 2023.  
5. Pacalet, R. â€“ *Project S5*, 2022.

---

